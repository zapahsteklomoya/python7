{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGEXxcdEFZzE"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtwPQQ4hFZzG"
      },
      "source": [
        "Материалы:\n",
        "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
        "* https://realpython.com/nltk-nlp-python/\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WjVXIcWFZzG"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wIC5c5taFZzG"
      },
      "outputs": [],
      "source": [
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RjzrB_sFZzH"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc9Wkz-8FZzH",
        "outputId": "0a2a1dae-1798-4980-c019-5abfb1ba48d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий\n",
            "с величайшим усилием выбравшись из потока убегающих людей кутузов со свитой уменьшившейся вдвое поехал на звуки выстрелов русских орудий\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/litw-win_new.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    words = f.read().split()\n",
        "\n",
        "\n",
        "def levenshtein_distance(s1, s2):\n",
        "    if len(s1) < len(s2):\n",
        "        return levenshtein_distance(s2, s1)\n",
        "\n",
        "    if len(s2) == 0:\n",
        "        return len(s1)\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "        previous_row = current_row\n",
        "\n",
        "    return previous_row[-1]\n",
        "\n",
        "\n",
        "def correct_typo(word, words_list):\n",
        "    min_distance = float(\"inf\")\n",
        "    closest_word = word\n",
        "\n",
        "    for w in words_list:\n",
        "        distance = levenshtein_distance(word, w)\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            closest_word = w\n",
        "\n",
        "    return closest_word\n",
        "\n",
        "\n",
        "corrected_text = []\n",
        "for word in text.split():\n",
        "    if word in words:\n",
        "        corrected_text.append(word)\n",
        "    else:\n",
        "        corrected_text.append(correct_typo(word, words))\n",
        "\n",
        "corrected_text = \" \".join(corrected_text)\n",
        "print(text)\n",
        "print(corrected_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIAPtEhTFZzI"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHBuo0M8I1Ps",
        "outputId": "5382d0a4-53ef-4bf3-b93e-60284a6fac27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=327483082c3e8124fb3eda75703d732397a545d795bced441ce05c7b3fd8b17e\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KTZUmWTPFZzI"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pymorphy2 import MorphAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRfiQjGpFZzI",
        "outputId": "bef1a37c-1678-462d-f242-8bbce076853f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['с', 'величайш', 'усил', 'выбра', 'из', 'поток', 'убега', 'люд', 'кутуз', 'со', 'свит', 'уменьш', 'вдво', 'поеха', 'на', 'звук', 'выстрел', 'русск', 'оруд']\n",
            "['с', 'великий', 'усилие', 'выбраться', 'из', 'поток', 'убегать', 'человек', 'кутузов', 'с', 'свита', 'уменьшиться', 'вдвое', 'поехать', 'на', 'звук', 'выстрел', 'русский', 'орудие']\n"
          ]
        }
      ],
      "source": [
        "words = corrected_text.split()\n",
        "\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
        "\n",
        "print(stemmed_words)\n",
        "print(lemmatized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw9g258NFZzI"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI94EozwFZzI",
        "outputId": "f237a63c-d0f5-46ee-89fa-e1e8df36a3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['вдвое' 'величайшим' 'выбравшись' 'выстрелов' 'звуки' 'из' 'кутузов'\n",
            " 'людей' 'на' 'орудий' 'поехал' 'потока' 'русских' 'свитой' 'со'\n",
            " 'убегающих' 'уменьшившейся' 'усилием']\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform([corrected_text])\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt9gWkDpFZzJ"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI80XzkXFZzJ"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4an0sWrFZzJ"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UidO_kUsFZzJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.metrics.distance import edit_distance\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeoaBcgSFZzJ"
      },
      "outputs": [],
      "source": [
        "# Загрузка предобработанных описаний рецептов из файла\n",
        "df = pd.read_csv('data/recipes_sample.csv')\n",
        "descriptions = df['description'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5hsWcm4FZzJ"
      },
      "outputs": [],
      "source": [
        "# Получение набора уникальных слов\n",
        "words = set()\n",
        "for description in descriptions:\n",
        "    if pd.isna(description):\n",
        "        continue\n",
        "    tokens = word_tokenize(description)\n",
        "    words.update(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgqCX5EeFZzJ"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hblz06PCFZzJ",
        "outputId": "73dc72cd-341f-41fb-e592-4513db82eb9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Расстояние редактирования между словами \"bakeoff\" и \"sits\" равно 7\n",
            "Расстояние редактирования между словами \"mits\" и \"taquito\" равно 5\n",
            "Расстояние редактирования между словами \"spiciness\" и \"browns\" равно 7\n",
            "Расстояние редактирования между словами \"-so\" и \"dessert.prep/cook\" равно 15\n",
            "Расстояние редактирования между словами \"147254\" и \"gain\" равно 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_31408\\1417854365.py:3: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  word1, word2 = random.sample(words, 2)\n"
          ]
        }
      ],
      "source": [
        "# Генерация 5 пар случайно выбранных слов и подсчет расстояния редактирования между ними\n",
        "for i in range(5):\n",
        "    word1, word2 = random.sample(words, 2)\n",
        "    distance = edit_distance(word1, word2)\n",
        "    print(f'Расстояние редактирования между словами \"{word1}\" и \"{word2}\" равно {distance}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw8yJ8axFZzJ"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz3hP855FZzJ"
      },
      "outputs": [],
      "source": [
        "def find_closest_words(word, words, k):\n",
        "    distances = [(edit_distance(word, w), w) for w in words]\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "    closest_words = [w[1] for w in distances[:k]]\n",
        "    return closest_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btm4Ml9OFZzJ",
        "outputId": "2839c8ba-bcfb-4d8f-e8de-09d5d42674d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 ближайших слов к 'processing': ['processing', 'pressing', 'proceeding', 'processer', 'processor/']\n"
          ]
        }
      ],
      "source": [
        "word = \"processing\"\n",
        "k = 5\n",
        "closest_words = find_closest_words(word, words, 5)\n",
        "print(f\"{k} ближайших слов к '{word}': {closest_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeuXTGzVFZzK"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jcS459zFZzK"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
        "    * word\n",
        "    * stemmed_word \n",
        "    * normalized_word \n",
        "\n",
        "Столбец `word` укажите в качестве индекса. \n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieFJZ26KFZzK"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKm0AHG6FZzK"
      },
      "outputs": [],
      "source": [
        "# Создание pd.DataFrame со столбцами word, stemmed_word и normalized_word\n",
        "stemmer = SnowballStemmer('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "data = []\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    normalized_word = lemmatizer.lemmatize(word)\n",
        "    data.append([word, stemmed_word, normalized_word])\n",
        "\n",
        "df_words = pd.DataFrame(data, columns=['word', 'stemmed_word', 'normalized_word'])\n",
        "df_words.set_index('word', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGdsofntFZzK",
        "outputId": "ee147678-fce3-4e2c-cc2e-524a8d5b2702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 stemmed_word normalized_word\n",
            "word                                         \n",
            "low-sugar           low-sugar       low-sugar\n",
            "comstock             comstock        comstock\n",
            "purdy                   purdi           purdy\n",
            "lunchroom           lunchroom       lunchroom\n",
            "cook.there          cook.ther      cook.there\n",
            "1/2-centimetre  1/2-centimetr  1/2-centimetre\n",
            "kall                     kall            kall\n",
            "engine                  engin          engine\n",
            "mizrahi               mizrahi         mizrahi\n",
            "b4                         b4              b4\n"
          ]
        }
      ],
      "source": [
        "# Сравнение результатов стемминга и лемматизации\n",
        "print(df_words.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAjKqqY0FZzK"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLSnhib1FZzK",
        "outputId": "412179c2-7710-4145-eb02-4674a7990303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Доля стоп-слов: 40.26%\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Удаление стоп-слов из описаний рецептов\n",
        "filtered_descriptions = []\n",
        "for description in descriptions:\n",
        "    if pd.isna(description):\n",
        "        continue\n",
        "    tokens = word_tokenize(description)\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "    filtered_description = ' '.join(filtered_tokens)\n",
        "    filtered_descriptions.append(filtered_description)\n",
        "\n",
        "# Подсчет доли стоп-слов\n",
        "total_words = sum(len(word_tokenize(description)) for description in descriptions if not pd.isna(description))\n",
        "total_filtered_words = sum(len(word_tokenize(description)) for description in filtered_descriptions)\n",
        "stop_words_ratio = (total_words - total_filtered_words) / total_words\n",
        "print(f'Доля стоп-слов: {stop_words_ratio:.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85nyu_XeFZzK",
        "outputId": "9f817488-2f50-4642-b43b-f523a9544e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Топ-10 самых часто употребляемых слов до удаления стоп-слов:\n",
            ".: 66166\n",
            "the: 40257\n",
            ",: 38544\n",
            "a: 35030\n",
            "and: 30425\n",
            "i: 27799\n",
            "this: 27132\n",
            "to: 23508\n",
            "it: 23212\n",
            "is: 20501\n",
            "Топ-10 самых часто употребляемых слов после удаления стоп-слов:\n",
            ".: 66260\n",
            ",: 38544\n",
            "!: 16054\n",
            "recipe: 15122\n",
            "'s: 7689\n",
            "make: 6367\n",
            "``: 5470\n",
            "time: 5198\n",
            "n't: 4798\n",
            "use: 4645\n"
          ]
        }
      ],
      "source": [
        "# Сравнение топ-10 самых часто употребляемых слов до и после удаления стоп-слов\n",
        "all_words = [word for description in descriptions if not pd.isna(description) for word in word_tokenize(description)]\n",
        "all_filtered_words = [word for description in filtered_descriptions for word in word_tokenize(description)]\n",
        "\n",
        "top_words = Counter(all_words).most_common(10)\n",
        "top_filtered_words = Counter(all_filtered_words).most_common(10)\n",
        "\n",
        "print('Топ-10 самых часто употребляемых слов до удаления стоп-слов:')\n",
        "for word, count in top_words:\n",
        "    print(f'{word}: {count}')\n",
        "\n",
        "print('Топ-10 самых часто употребляемых слов после удаления стоп-слов:')\n",
        "for word, count in top_filtered_words:\n",
        "    print(f'{word}: {count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NePK-1FYFZzK"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjDGJblsFZzL"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDeqmtVNFZzL",
        "outputId": "675274d2-804e-4ea5-bb09-6d009e892972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Описание рецепта: fantastic chili recipe.   you can use dried ancho, pasilla, adobo or other peppers.   \n",
            "\n",
            "pasilla is a good choice for a mild level of spice.  use bottled hot sauce per bowl to kick it up for the real heat lovers.\n",
            "\n",
            "\n",
            "this recipe copied from the following url:  \n",
            "\n",
            "http://www.greatchilirecipes.net/awful_good_texas_chili.html  \n",
            "\n",
            "stored here as insurance in case the original site ever disappears.\n",
            "Вектор: [0.         0.         0.         0.12326683 0.12326683 0.\n",
            " 0.         0.12326683 0.12326683 0.         0.12326683 0.12326683\n",
            " 0.         0.         0.         0.08255323 0.12326683 0.\n",
            " 0.12326683 0.12326683 0.         0.         0.         0.12326683\n",
            " 0.         0.         0.         0.         0.12326683 0.\n",
            " 0.12326683 0.         0.12326683 0.12326683 0.         0.12326683\n",
            " 0.1989018  0.0994509  0.12326683 0.         0.12326683 0.12326683\n",
            " 0.12326683 0.12326683 0.12326683 0.12326683 0.08255323 0.\n",
            " 0.12326683 0.0994509  0.08255323 0.12326683 0.12326683 0.\n",
            " 0.12326683 0.         0.12326683 0.         0.         0.12326683\n",
            " 0.12326683 0.12326683 0.12326683 0.12326683 0.         0.\n",
            " 0.24653365 0.         0.12326683 0.12326683 0.         0.\n",
            " 0.         0.         0.12326683 0.24653365 0.         0.\n",
            " 0.         0.12326683 0.         0.         0.         0.12326683\n",
            " 0.         0.         0.         0.12326683 0.         0.12326683\n",
            " 0.         0.         0.2983527  0.08255323 0.         0.0994509\n",
            " 0.         0.12326683 0.12326683 0.1989018  0.         0.\n",
            " 0.         0.12326683 0.12326683]\n",
            "Описание рецепта: crispy and tasty shrimp!\n",
            "Вектор: [0.         0.         0.         0.         0.         0.38040565\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.56801408 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.56801408 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.45827018 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.        ]\n",
            "Описание рецепта: this delicious pasta dish features chicken and spinach with mushrooms. it's a great weeknight meal that can be prepared and served in under 15 minutes. created for rsc #11. buon appetito!\n",
            "Вектор: [0.19671213 0.19671213 0.         0.         0.         0.26348081\n",
            " 0.19671213 0.         0.         0.15870611 0.         0.\n",
            " 0.19671213 0.         0.         0.13174041 0.         0.19671213\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.19671213 0.         0.         0.15870611 0.         0.15870611\n",
            " 0.         0.         0.         0.         0.19671213 0.\n",
            " 0.15870611 0.         0.         0.15870611 0.         0.\n",
            " 0.         0.         0.         0.         0.13174041 0.\n",
            " 0.         0.         0.13174041 0.         0.         0.\n",
            " 0.         0.19671213 0.         0.19671213 0.19671213 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.19671213 0.         0.         0.         0.19671213\n",
            " 0.         0.         0.         0.         0.         0.19671213\n",
            " 0.         0.         0.19671213 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.19671213 0.\n",
            " 0.         0.19671213 0.         0.13174041 0.         0.\n",
            " 0.19671213 0.         0.         0.         0.         0.19671213\n",
            " 0.19671213 0.         0.        ]\n",
            "Описание рецепта: this dish is inspired by the spanish classic paella and is cooked from raw in the oven. the rice can be a little soft, cooking it this way but it's absolutely delicious and so easy!\n",
            "Вектор: [0.         0.         0.17150948 0.         0.         0.22972379\n",
            " 0.         0.         0.         0.13837277 0.         0.\n",
            " 0.         0.17150948 0.17150948 0.1148619  0.         0.\n",
            " 0.         0.         0.17150948 0.17150948 0.17150948 0.\n",
            " 0.         0.         0.         0.13837277 0.         0.13837277\n",
            " 0.         0.17150948 0.         0.         0.         0.\n",
            " 0.         0.13837277 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1148619  0.17150948\n",
            " 0.         0.27674553 0.22972379 0.         0.         0.17150948\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.17150948 0.17150948\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.17150948 0.         0.         0.17150948 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.17150948 0.17150948 0.17150948 0.         0.         0.\n",
            " 0.         0.         0.4151183  0.22972379 0.         0.\n",
            " 0.         0.         0.         0.         0.13837277 0.\n",
            " 0.         0.         0.        ]\n",
            "Описание рецепта: cucumber salad. great side. tasty way to use those profuse cucumber plants.\n",
            "Вектор: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.57132177 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.2304694  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.28566088 0.\n",
            " 0.28566088 0.         0.         0.         0.         0.\n",
            " 0.28566088 0.         0.         0.         0.28566088 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.2304694  0.         0.         0.         0.28566088 0.2304694\n",
            " 0.         0.         0.         0.2304694  0.2304694  0.\n",
            " 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Выбор случайных 5 рецептов из набора данных\n",
        "random_rows = df.sample(5)\n",
        "random_descriptions = random_rows['description'].tolist()\n",
        "random_names = random_rows['name'].tolist()\n",
        "\n",
        "# Представление описаний рецептов в виде числовых векторов при помощи TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(random_descriptions)\n",
        "tfidf_vectors = tfidf_matrix.toarray()\n",
        "\n",
        "# Вывод результатов\n",
        "for i, description in enumerate(random_descriptions):\n",
        "    vector = tfidf_vectors[i]\n",
        "    print(f'Описание рецепта: {description}')\n",
        "    print(f'Вектор: {vector}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq-rSOeGFZzL"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAOogipYFZzL",
        "outputId": "c9b11705-14ec-4fd7-953a-0942fd7bb122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Близость между каждой парой рецептов:\n",
            "                                        texas chili  salt and pepper shrimp  farfalle con pollo e spinaci  baked spanish risotto  cucumber in vinegar  pickled cucumbers\n",
            "texas chili                                1.000000                0.000000                      0.075069               0.222029                                0.068761\n",
            "salt and pepper shrimp                     0.000000                1.000000                      0.100230               0.087388                                0.105617\n",
            "farfalle con pollo e spinaci               0.075069                0.100230                      1.000000               0.217201                                0.036577\n",
            "baked spanish risotto                      0.222029                0.087388                      0.217201               1.000000                                0.031891\n",
            "cucumber in vinegar  pickled cucumbers     0.068761                0.105617                      0.036577               0.031891                                1.000000\n"
          ]
        }
      ],
      "source": [
        "# Вычисление близости между каждой парой рецептов\n",
        "similarity_matrix = []\n",
        "for i in range(len(tfidf_vectors)):\n",
        "    row = []\n",
        "    for j in range(len(tfidf_vectors)):\n",
        "        similarity = 1 - cosine(tfidf_vectors[i], tfidf_vectors[j])\n",
        "        row.append(similarity)\n",
        "    similarity_matrix.append(row)\n",
        "\n",
        "# Создание таблицы pd.DataFrame с результатами\n",
        "df_similarity = pd.DataFrame(similarity_matrix, index=random_names, columns=random_names)\n",
        "\n",
        "# Вывод результатов\n",
        "print('Близость между каждой парой рецептов:')\n",
        "print(df_similarity.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL2P67hBFZzL"
      },
      "source": [
        "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1mZ7RAIFZzL"
      },
      "source": [
        "На основе представленной таблицы близости между каждой парой рецептов можно сделать вывод, что наиболее похожими являются рецепты “texas chili” и “baked spanish risotto”, так как значение близости между ними равно 0.222029, что является наибольшим значением в таблице. Это означает, что описания этих двух рецептов имеют наибольшее сходство среди всех выбранных рецептов.\n",
        "\n",
        "Однако стоит отметить, что значения близости между всеми парами рецептов достаточно низкие, что указывает на то, что описания всех выбранных рецептов достаточно различны друг от друга."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}